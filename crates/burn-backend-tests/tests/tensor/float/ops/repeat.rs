use super::*;
use burn_tensor::TensorData;

#[test]
fn should_support_repeat_ops_one_dimension() {
    let data = TensorData::from([[0.0f32, 1.0f32, 2.0f32]]);
    let tensor = TestTensor::<2>::from_data(data, &Default::default());

    let output = tensor.repeat(&[4, 1, 1]);
    let expected = TensorData::from([
        [0.0f32, 1.0f32, 2.0f32],
        [0.0f32, 1.0f32, 2.0f32],
        [0.0f32, 1.0f32, 2.0f32],
        [0.0f32, 1.0f32, 2.0f32],
    ]);

    output.into_data().assert_eq(&expected, false);
}

#[test]
fn should_support_float_repeat_repeating_on_many_dimensions() {
    let data = TensorData::from([
        [[1.0f32, 2.0f32], [3.0f32, 4.0f32]],
        [[5.0f32, 6.0f32], [7.0f32, 8.0f32]],
        [[9.0f32, 10.0f32], [11.0f32, 12.0f32]],
        [[13.0f32, 14.0f32], [15.0f32, 16.0f32]],
    ]);
    let tensor = TestTensor::<3>::from_data(data, &Default::default());

    let output = tensor.repeat(&[2, 3, 2]);
    let expected = TensorData::from([
        [
            [1.0f32, 2.0f32, 1.0f32, 2.0f32],
            [3.0f32, 4.0f32, 3.0f32, 4.0f32],
            [1.0f32, 2.0f32, 1.0f32, 2.0f32],
            [3.0f32, 4.0f32, 3.0f32, 4.0f32],
            [1.0f32, 2.0f32, 1.0f32, 2.0f32],
            [3.0f32, 4.0f32, 3.0f32, 4.0f32],
        ],
        [
            [5.0f32, 6.0f32, 5.0f32, 6.0f32],
            [7.0f32, 8.0f32, 7.0f32, 8.0f32],
            [5.0f32, 6.0f32, 5.0f32, 6.0f32],
            [7.0f32, 8.0f32, 7.0f32, 8.0f32],
            [5.0f32, 6.0f32, 5.0f32, 6.0f32],
            [7.0f32, 8.0f32, 7.0f32, 8.0f32],
        ],
        [
            [9.0f32, 10.0f32, 9.0f32, 10.0f32],
            [11.0f32, 12.0f32, 11.0f32, 12.0f32],
            [9.0f32, 10.0f32, 9.0f32, 10.0f32],
            [11.0f32, 12.0f32, 11.0f32, 12.0f32],
            [9.0f32, 10.0f32, 9.0f32, 10.0f32],
            [11.0f32, 12.0f32, 11.0f32, 12.0f32],
        ],
        [
            [13.0f32, 14.0f32, 13.0f32, 14.0f32],
            [15.0f32, 16.0f32, 15.0f32, 16.0f32],
            [13.0f32, 14.0f32, 13.0f32, 14.0f32],
            [15.0f32, 16.0f32, 15.0f32, 16.0f32],
            [13.0f32, 14.0f32, 13.0f32, 14.0f32],
            [15.0f32, 16.0f32, 15.0f32, 16.0f32],
        ],
        [
            [1.0f32, 2.0f32, 1.0f32, 2.0f32],
            [3.0f32, 4.0f32, 3.0f32, 4.0f32],
            [1.0f32, 2.0f32, 1.0f32, 2.0f32],
            [3.0f32, 4.0f32, 3.0f32, 4.0f32],
            [1.0f32, 2.0f32, 1.0f32, 2.0f32],
            [3.0f32, 4.0f32, 3.0f32, 4.0f32],
        ],
        [
            [5.0f32, 6.0f32, 5.0f32, 6.0f32],
            [7.0f32, 8.0f32, 7.0f32, 8.0f32],
            [5.0f32, 6.0f32, 5.0f32, 6.0f32],
            [7.0f32, 8.0f32, 7.0f32, 8.0f32],
            [5.0f32, 6.0f32, 5.0f32, 6.0f32],
            [7.0f32, 8.0f32, 7.0f32, 8.0f32],
        ],
        [
            [9.0f32, 10.0f32, 9.0f32, 10.0f32],
            [11.0f32, 12.0f32, 11.0f32, 12.0f32],
            [9.0f32, 10.0f32, 9.0f32, 10.0f32],
            [11.0f32, 12.0f32, 11.0f32, 12.0f32],
            [9.0f32, 10.0f32, 9.0f32, 10.0f32],
            [11.0f32, 12.0f32, 11.0f32, 12.0f32],
        ],
        [
            [13.0f32, 14.0f32, 13.0f32, 14.0f32],
            [15.0f32, 16.0f32, 15.0f32, 16.0f32],
            [13.0f32, 14.0f32, 13.0f32, 14.0f32],
            [15.0f32, 16.0f32, 15.0f32, 16.0f32],
            [13.0f32, 14.0f32, 13.0f32, 14.0f32],
            [15.0f32, 16.0f32, 15.0f32, 16.0f32],
        ],
    ]);

    output.into_data().assert_eq(&expected, false);
}

#[test]
fn should_repeat_0_times_empty() {
    let tensor = TestTensor::<3>::ones([2, 3, 4], &Default::default());

    let output = tensor.repeat(&[1, 0, 2]);

    assert_eq!(output.shape(), [2, 0, 8].into());
}
