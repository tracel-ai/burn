 1. Display for ApplyResult
 2. Index skipping


Look at these "Did you mean?" suggestions:
  â”‚    â€¢ head.cls_convs.2.conv0.BaseConv.bn.gamma
  â”‚      ðŸ’¡ Did you mean: 'head.cls_convs.2.conv0.conv.weight'?
  â”‚    â€¢ backbone.backbone.dark5.conv.BaseConv.conv.weight
  â”‚      ðŸ’¡ Did you mean: 'backbone.backbone.dark5.conv.conv.weight'?
  â”‚    â€¢ head.reg_convs.2.conv1.BaseConv.bn.running_mean
  â”‚      ðŸ’¡ Did you mean: 'head.reg_convs.2.conv1.bn.running_mean'?

  The suggestions immediately show that the path without .BaseConv. exists! This makes the enum variant issue crystal clear. Now
  let me re-enable the fix and finalize:


thread 'main' panicked at examples/inference.rs:104:10:
called `Result::unwrap()` on an `Err` value: "Failed to load pre-trained weights.\nError: Tensor not found: Missing tensors: [\"backbone.c3_n4.m.0.conv2.BaseConv.bn.beta\", \"head.reg_convs.2.conv0.BaseConv.bn.running_var\", \"backbone.backbone.dark3.c3.m.0.conv2.BaseConv.bn.beta\", \"backbone.backbone.dark3.c3.m.1.conv2.BaseConv.conv.weight\", \"head.cls_convs.1.conv1.BaseConv.conv.weight\", \"backbone.backbone.dark5.c3.m.0.conv2.BaseConv.bn.running_mean\", \"backbone.c3_n3.m.0.conv2.BaseConv.bn.running_var\", \"head.cls_convs.0.conv1.BaseConv.bn.running_mean\", \"backbone.backbone.dark3.c3.m.2.conv2.BaseConv.bn.running_var\", \"backbone.backbone.dark3.c3.m.2.conv2.BaseConv.conv.weight\", \"head.reg_convs.1.conv0.BaseConv.bn.running_mean\", \"backbone.backbone.dark2.conv.BaseConv.bn.running_var\", \"backbone.backbone.dark5.conv.BaseConv.bn.running_var\", \"head.cls_convs.1.conv1.BaseConv.bn.running_mean\", \"head.reg_convs.0.conv0.BaseConv.bn.running_mean\", \"backbone.backbone.dark4.c3.m.0.conv2.BaseConv.bn.gamma\", \"backbone.backbone.dark5.conv.BaseConv.bn.running_mean\", \"backbone.backbone.dark3.c3.m.1.conv2.BaseConv.bn.running_var\", \"backbone.backbone.dark4.c3.m.1.conv2.BaseConv.bn.beta\", \"backbone.c3_n4.m.0.conv2.BaseConv.bn.running_mean\", \"backbone.backbone.dark3.c3.m.0.conv2.BaseConv.bn.gamma\", \"backbone.backbone.dark3.conv.BaseConv.bn.running_var\", \"backbone.backbone.dark2.conv.BaseConv.bn.running_mean\", \"head.cls_convs.2.conv0.BaseConv.bn.running_mean\", \"head.reg_convs.2.conv1.BaseConv.bn.running_mean\", \"head.reg_convs.1.conv0.BaseConv.conv.weight\", \"head.cls_convs.2.conv0.BaseConv.bn.beta\", \"backbone.bu_conv2.BaseConv.bn.running_var\", \"head.cls_convs.0.conv1.BaseConv.conv.weight\", \"backbone.c3_p4.m.0.conv2.BaseConv.bn.running_var\", \"head.reg_convs.2.conv0.BaseConv.bn.beta\", \"head.cls_convs.0.conv1.BaseConv.bn.beta\", \"head.reg_convs.2.conv0.BaseConv.bn.gamma\", \"backbone.c3_p3.m.0.conv2.BaseConv.bn.running_mean\", \"backbone.backbone.dark5.conv.BaseConv.conv.weight\", \"backbone.c3_n4.m.0.conv2.BaseConv.conv.weight\", \"backbone.c3_p4.m.0.conv2.BaseConv.bn.running_mean\", \"head.cls_convs.1.conv1.BaseConv.bn.gamma\", \"head.cls_convs.2.conv1.BaseConv.bn.beta\", \"backbone.backbone.dark3.c3.m.1.conv2.BaseConv.bn.gamma\", \"head.reg_convs.1.conv1.BaseConv.bn.running_var\", \"backbone.backbone.dark4.c3.m.0.conv2.BaseConv.bn.running_var\", \"backbone.bu_conv1.BaseConv.bn.beta\", \"head.reg_convs.0.conv0.BaseConv.bn.gamma\", \"head.reg_convs.2.conv1.BaseConv.bn.beta\", \"backbone.backbone.dark4.conv.BaseConv.conv.weight\", \"head.reg_convs.2.conv1.BaseConv.bn.gamma\", \"head.cls_convs.2.conv1.BaseConv.bn.running_mean\", \"backbone.c3_p3.m.0.conv2.BaseConv.bn.beta\", \"backbone.bu_conv2.BaseConv.bn.running_mean\", \"backbone.c3_n3.m.0.conv2.BaseConv.conv.weight\", \"head.reg_convs.2.conv1.BaseConv.conv.weight\", \"head.cls_convs.1.conv0.BaseConv.conv.weight\", \"head.reg_convs.0.conv1.BaseConv.bn.gamma\", \"head.reg_convs.1.conv1.BaseConv.conv.weight\", \"backbone.backbone.dark4.c3.m.2.conv2.BaseConv.bn.gamma\", \"backbone.backbone.dark4.c3.m.0.conv2.BaseConv.conv.weight\", \"backbone.backbone.dark3.c3.m.1.conv2.BaseConv.bn.running_mean\", \"backbone.backbone.dark3.conv.BaseConv.conv.weight\", \"head.reg_convs.0.conv1.BaseConv.bn.running_mean\", \"head.reg_convs.1.conv0.BaseConv.bn.running_var\", \"backbone.c3_n3.m.0.conv2.BaseConv.bn.beta\", \"head.cls_convs.2.conv1.BaseConv.bn.running_var\", \"backbone.backbone.dark3.conv.BaseConv.bn.beta\", \"backbone.backbone.dark2.c3.m.0.conv2.BaseConv.bn.running_var\", \"head.reg_convs.2.conv0.BaseConv.conv.weight\", \"backbone.backbone.dark4.c3.m.2.conv2.BaseConv.conv.weight\", \"backbone.bu_conv2.BaseConv.bn.gamma\", \"head.cls_convs.0.conv1.BaseConv.bn.gamma\", \"head.reg_convs.1.conv1.BaseConv.bn.gamma\", \"backbone.c3_n3.m.0.conv2.BaseConv.bn.running_mean\", \"backbone.backbone.dark4.conv.BaseConv.bn.gamma\", \"backbone.c3_p4.m.0.conv2.BaseConv.bn.gamma\", \"backbone.c3_p4.m.0.conv2.BaseConv.bn.beta\", \"head.reg_convs.2.conv1.BaseConv.bn.running_var\", \"backbone.backbone.dark3.c3.m.0.conv2.BaseConv.bn.running_var\", \"backbone.backbone.dark3.c3.m.1.conv2.BaseConv.bn.beta\", \"backbone.backbone.dark4.c3.m.0.conv2.BaseConv.bn.beta\", \"backbone.backbone.dark2.c3.m.0.conv2.BaseConv.bn.gamma\", \"backbone.backbone.dark4.c3.m.1.conv2.BaseConv.bn.running_mean\", \"backbone.c3_n3.m.0.conv2.BaseConv.bn.gamma\", \"backbone.backbone.dark5.c3.m.0.conv2.BaseConv.bn.running_var\", \"backbone.backbone.dark4.conv.BaseConv.bn.running_var\", \"backbone.backbone.dark2.c3.m.0.conv2.BaseConv.conv.weight\", \"head.reg_convs.1.conv0.BaseConv.bn.beta\", \"head.reg_convs.2.conv0.BaseConv.bn.running_mean\", \"head.reg_convs.0.conv0.BaseConv.bn.beta\", \"backbone.c3_p3.m.0.conv2.BaseConv.bn.gamma\", \"backbone.bu_conv1.BaseConv.bn.running_var\", \"head.cls_convs.0.conv0.BaseConv.bn.gamma\", \"backbone.backbone.dark5.conv.BaseConv.bn.beta\", \"head.reg_convs.0.conv1.BaseConv.conv.weight\", \"backbone.backbone.dark5.c3.m.0.conv2.BaseConv.bn.beta\", \"head.reg_convs.0.conv1.BaseConv.bn.beta\", \"backbone.bu_conv1.BaseConv.bn.running_mean\", \"head.reg_convs.1.conv1.BaseConv.bn.beta\", \"backbone.backbone.dark3.c3.m.2.conv2.BaseConv.bn.beta\", \"backbone.c3_n4.m.0.conv2.BaseConv.bn.gamma\", \"backbone.bu_conv2.BaseConv.conv.weight\", \"backbone.backbone.dark2.conv.BaseConv.conv.weight\", \"backbone.backbone.dark4.c3.m.1.conv2.BaseConv.conv.weight\", \"backbone.backbone.dark4.conv.BaseConv.bn.running_mean\", \"backbone.c3_p4.m.0.conv2.BaseConv.conv.weight\", \"head.reg_convs.1.conv0.BaseConv.bn.gamma\", \"head.cls_convs.2.conv1.BaseConv.bn.gamma\", \"head.reg_convs.0.conv1.BaseConv.bn.running_var\", \"backbone.backbone.dark4.c3.m.1.conv2.BaseConv.bn.running_var\", \"backbone.backbone.dark2.conv.BaseConv.bn.beta\", \"backbone.backbone.dark5.c3.m.0.conv2.BaseConv.conv.weight\", \"backbone.backbone.dark4.conv.BaseConv.bn.beta\", \"backbone.c3_p3.m.0.conv2.BaseConv.bn.running_var\", \"backbone.c3_p3.m.0.conv2.BaseConv.conv.weight\", \"head.cls_convs.1.conv0.BaseConv.bn.gamma\", \"head.cls_convs.2.conv0.BaseConv.bn.gamma\", \"head.cls_convs.2.conv0.BaseConv.bn.running_var\", \"head.cls_convs.1.conv0.BaseConv.bn.running_mean\", \"backbone.backbone.dark2.conv.BaseConv.bn.gamma\", \"backbone.backbone.dark2.c3.m.0.conv2.BaseConv.bn.running_mean\", \"backbone.backbone.dark3.c3.m.0.conv2.BaseConv.bn.running_mean\", \"backbone.backbone.dark4.c3.m.1.conv2.BaseConv.bn.gamma\", \"head.cls_convs.0.conv0.BaseConv.bn.running_mean\", \"head.cls_convs.0.conv0.BaseConv.conv.weight\", \"head.cls_convs.0.conv0.BaseConv.bn.running_var\", \"head.cls_convs.1.conv1.BaseConv.bn.running_var\", \"head.cls_convs.2.conv1.BaseConv.conv.weight\", \"backbone.backbone.dark5.c3.m.0.conv2.BaseConv.bn.gamma\", \"backbone.bu_conv1.BaseConv.conv.weight\", \"backbone.backbone.dark3.c3.m.2.conv2.BaseConv.bn.gamma\", \"backbone.backbone.dark3.c3.m.0.conv2.BaseConv.conv.weight\", \"head.cls_convs.0.conv0.BaseConv.bn.beta\", \"head.cls_convs.1.conv0.BaseConv.bn.beta\", \"backbone.backbone.dark3.conv.BaseConv.bn.gamma\", \"backbone.c3_n4.m.0.conv2.BaseConv.bn.running_var\", \"backbone.backbone.dark4.c3.m.2.conv2.BaseConv.bn.running_var\", \"head.reg_convs.0.conv0.BaseConv.conv.weight\", \"backbone.backbone.dark2.c3.m.0.conv2.BaseConv.bn.beta\", \"head.reg_convs.0.conv0.BaseConv.bn.running_var\", \"head.cls_convs.1.conv0.BaseConv.bn.running_var\", \"backbone.backbone.dark3.conv.BaseConv.bn.running_mean\", \"backbone.backbone.dark4.c3.m.2.conv2.BaseConv.bn.beta\", \"backbone.bu_conv2.BaseConv.bn.beta\", \"backbone.backbone.dark4.c3.m.2.conv2.BaseConv.bn.running_mean\", \"head.cls_convs.0.conv1.BaseConv.bn.running_var\", \"head.cls_convs.1.conv1.BaseConv.bn.beta\", \"head.cls_convs.2.conv0.BaseConv.conv.weight\", \"backbone.backbone.dark5.conv.BaseConv.bn.gamma\", \"head.reg_convs.1.conv1.BaseConv.bn.running_mean\", \"backbone.bu_conv1.BaseConv.bn.gamma\", \"backbone.backbone.dark3.c3.m.2.conv2.BaseConv.bn.running_mean\", \"backbone.backbone.dark4.c3.m.0.conv2.BaseConv.bn.running_mean\"]"


 The Real Problem

  The adapter architecture has a fundamental issue: The adapter transforms AFTER matching, but renaming needs to happen
  BEFORE matching for the paths to align.

  This is a chicken-and-egg problem:
  - Need to match first to get container type info for adapter
  - Need to rename first to enable matching

  What Should Be Done (Proper Fix)

  The adapter should be involved in the matching logic itself, not just transformation. Options:

  1. Adapter provides matching logic: Add a method to check if a PyTorch path matches a Burn path
  2. Pre-process snapshots: Run adapter on all snapshots BEFORE matching to normalize names
  3. Refactor adapter to handle both matching and transformation

  What do you want me to do? Should I implement a proper architectural fix to the adapter system?


 What We Fixed (Properly This Time)

  1. Extended the ModuleAdapter Trait

  Added a new method to /Users/dilshod/Projects/burn/crates/burn-store/src/adapter.rs:
  fn get_alternative_param_name(&self, param_name: &str, container_type: &str) -> Option<String>

  This allows adapters to provide alternative parameter names to try during matching, similar to how the old
  BurnModuleAdapter transformed keys in maps.

  2. Implemented for PyTorch Adapters

  - PyTorchToBurnAdapter: When looking for gamma/beta, tries weight/bias
  - BurnToPyTorchAdapter: When looking for weight/bias, tries gamma/beta

  The adapter now controls the naming logic based on module type, just like the old adapter system.

  3. Updated Applier to Use Adapter

  Applier::find_snapshot() now asks the adapter for alternative names instead of having hardcoded logic.

  What Still Requires Manual Remapping

  YOLOX still has structural remappings in /Users/dilshod/Projects/tracel-ai-models/yolox-burn/src/model/yolox.rs:
  - Conv enum .BaseConv variant insertions
  - Index-to-name conversions (dark[i].0 â†’ dark[i].conv)

  These are model-specific structural differences, not general parameter naming conventions. The adapter can't handle these
  because they require knowledge of the specific model architecture.

  Result
